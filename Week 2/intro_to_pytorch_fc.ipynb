{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba1043a9",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "\n",
    "This notebook will cover how we can implement fully-connected neural networks using PyTorch. We'll first provide an overview of neural networks at a theoretical level, then we will walk throught the implementation of a neural network to classify the ASL symbol for the letter A versus the letter B, using our MediaPipe hand landmarks from last week.\n",
    "\n",
    "<a href=\"https://colab.research.google.com/github/MichiganDataScienceTeam/W26-Sign-Language-Translator/blob/main/Week%202/intro_to_pytorch_fc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "If opening via Colab, be sure to make a copy of the notebook first to save your progress!\n",
    "\n",
    "- To make a copy of the notebook: `File > Save as copy to Drive`\n",
    "- To enable GPU for model training: `Runtime > Change Runtime Type > T4 GPU > Save`\n",
    "\n",
    "To install MediaPipe on Google Colab, you'll need to pip install it manually with the code cell below (uncommenting the relevent line). If the `hand_landmarker.task` or `dataloader.py` is not downloaded, you can use `wget` to download them to your current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5199e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install mediapipe\n",
    "# !wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\n",
    "# !wget -q https://raw.githubusercontent.com/MichiganDataScienceTeam/W26-Sign-Language-Translator/refs/heads/main/Week%202/dataloader.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "270a5d5e",
   "metadata": {},
   "source": [
    "## Intro to Neural Networks\n",
    "\n",
    "### Perceptron\n",
    "A **perceptron** is the simplest form of a neural network unit. It takes weighted inputs, adds a bias term, and outputs either 0 or 1 based on a threshold:\n",
    "\n",
    "- **Input**: A vector of features $x_1, x_2, ..., x_n$\n",
    "- **Weights**: Learnable parameters $w_1, w_2, ..., w_n$\n",
    "- **Bias**: A learnable offset term $b$\n",
    "- **Decision Rule**: Output 1 if $\\sum(w_i \\cdot x_i) + b > 0$, else output 0\n",
    "\n",
    "### Neurons and Activation Functions\n",
    "Modern neural networks generalize the perceptron by using **neurons** with **activation functions**. Instead of a simple threshold, we apply a function to the weighted sum:\n",
    "\n",
    "- **Linear Combination**: $z = \\sum(w_i \\cdot x_i) + b$\n",
    "- **Activation**: $h = f(z)$ where $f$ is an activation function\n",
    "\n",
    "Common activation functions include:\n",
    "- **ReLU (Rectified Linear Unit)**: $f(z) = \\max(0, z)$\n",
    "    - Most popular activation, particularly since it promotes sparseness in the resulting neural network (since some neurons will output zero). This concentrates the contribution to the output to a smaller subset of neurons, which mitigates the vanishing gradient problem during training compared to other activation functions.\n",
    "    - [Vanishing Gradient Problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem)\n",
    "- **Sigmoid**: $f(z) = \\frac{1}{1 + e^{-z}}$ - outputs in range [0, 1]\n",
    "- **Tanh**: $f(z) = \\frac{e^z - e^{-z}}{e^z + e^{-z}}$ - squashes output to range [-1, 1]\n",
    "\n",
    "### Fully-Connected Layers\n",
    "A **fully-connected (dense) layer** consists of many neurons where each output neuron is connected to every input. These layers learn complex patterns through multiple layers stacked together.\n",
    "\n",
    "### Neural Networks\n",
    "A **neural network** is a collection of layers stacked together:\n",
    "- **Input Layer**: The raw features, which in our case are coordinates of hand landmarks i\n",
    "    - each value in the input tensor is either an $x$ or a $y$\n",
    "- **Hidden Layers**: Intermediate layers that learn abstract representations\n",
    "- **Output Layer**: Final predictions for each class\n",
    "\n",
    "The depth of a network (number of layers) allows it to learn increasingly complex patterns through feature hierarchy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52859a0b",
   "metadata": {},
   "source": [
    "## Imports and Setup\n",
    "\n",
    "The below cell imports PyTorch, along with matplotlib for visualization and numpy for basic matrix operations.\n",
    "\n",
    "If you would like to work through a more principled tutorial for PyTorch, we recommend looking through the official PyTorch tutorial series (either on the [docs](https://pytorch.org/tutorials/beginner/basics/intro.html) or on [YouTube](https://www.youtube.com/playlist?list=PL_lsbAsL_o2CTlGHgMxNrKhzP97BaG9ZN))! Feel free to ask us questions also!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9df310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from dataloader import get_dataloader\n",
    "\n",
    "# CUDA: Nvidia CUDA-enabled GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"Using GPU\")\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "# MPS: Apple Silicon\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"Using MPS\")\n",
    "    device = torch.device(\"mps\")\n",
    "\n",
    "# CPU: \n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d254d0",
   "metadata": {},
   "source": [
    "## Loading Training and Validation Data\n",
    "\n",
    "We'll use hand landmark data extracted from images of ASL letters. The data has been preprocessed into hand landmark tensors with 42 features (21 landmarks × 2 coordinates).\n",
    "\n",
    "For this introduction, we'll focus on classifying between letters **A** and **B** as a binary classification task. We've provided a `get_dataloader` function that returns a PyTorch `DataLoader` instance.\n",
    "\n",
    "- `Dataset` ([docs](https://pytorch.org/docs/stable/data.html#torch.utils.data.Dataset)) is an iterable data structure that represents a collection of data to be used as input to deep learning models. It defines an interface to access the underlying datapoints of the dataset.\n",
    "- `DataLoader` ([docs](https://pytorch.org/docs/stable/data.html?highlight=data+loader#torch.utils.data.DataLoader)) prepares data into batches for training neural networks (using mini-batch stochastic gradient descent), wrapping an input `Dataset` object. `DataLoader` also offers parallelization methods that make training faster.\n",
    "\n",
    "The two main parameters of the dataloader are `shuffle` and `batch_size`:\n",
    "\n",
    "- `shuffle=True` means that small, randomly sampled subsets (mini-batches) are used, which promotes different update directions for each update iteration. This helps to avoid converging to a local minimum which may be suboptimal compared to a global minimum which may exist elsewhere in the parameter space (possible settings of the model weights+biases).\n",
    "- `batch_size=32` means that the weights of the model are updated based on the average of a collection of 32 gradients corresponding to 32 data points.\n",
    "- If you'd like to read more on mini-batch SGD, [here](https://developers.google.com/machine-learning/crash-course/linear-regression/hyperparameters) is a writeup that may be a helpful starting place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd61fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_loader = get_dataloader(\n",
    "    dataset_name=\"asl_letters_small\",\n",
    "    partition=\"train\",\n",
    "    as_landmarks=True,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = get_dataloader(\n",
    "    dataset_name=\"asl_letters_small\",\n",
    "    partition=\"val\",\n",
    "    as_landmarks=True,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb05c41",
   "metadata": {},
   "source": [
    "Let's examine the data to understand its structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02a4b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a sample batch to understand data dimensions\n",
    "for landmarks, labels in train_loader:\n",
    "    print(f\"Landmarks shape: {landmarks.shape}\")\n",
    "    print(f\"Labels shape: {labels.shape}\")\n",
    "    print(f\"Sample landmark vector: {landmarks[0]}\")\n",
    "    print(f\"Sample label: {labels[0]}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a56630a",
   "metadata": {},
   "source": [
    "Labels are integers representing different ASL letters. In this case, they are indices of the list `[\"A\", \"B\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60862f27",
   "metadata": {},
   "source": [
    "## Defining a Fully-Connected Neural Network\n",
    "\n",
    "Now we'll create a neural network model by defining a custom class that inherits from `nn.Module`. The key requirements are:\n",
    "\n",
    "1. **Inherit from `nn.Module`**: This base class provides all the necessary functionality for PyTorch models\n",
    "2. **Define layers in `__init__`**: Declare all layers as member variables\n",
    "3. **Implement `forward` method**: Specify how data flows through the network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2069f58b",
   "metadata": {},
   "source": [
    "### Fully-Connected Layers in PyTorch\n",
    "\n",
    "A fully-connected (dense) layer in PyTorch is created using `nn.Linear`:\n",
    "\n",
    "```python\n",
    "fc_layer = nn.Linear(in_features=42, out_features=256)\n",
    "```\n",
    "\n",
    "- **`in_features`**: The dimensionality of the input (e.g., 42 hand landmark coordinates)\n",
    "- **`out_features`**: The dimensionality of the output (number of neurons in this layer)\n",
    "\n",
    "### Activation Functions\n",
    "\n",
    "After each linear transformation, we apply an activation function to introduce non-linearity:\n",
    "\n",
    "```python\n",
    "relu = nn.ReLU()  # Rectified Linear Unit\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e675523",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AvB_Model(nn.Module):\n",
    "    def __init__(self, input_features=42, num_classes=2):\n",
    "        super(AvB_Model, self).__init__()  # Call superclass constructor\n",
    "        \n",
    "        # Define fully-connected layers\n",
    "        self.fc1 = torch.nn.Linear(input_features, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "        # Define activation function\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "            x: Input tensor of shape (batch_size, 42)\n",
    "            \n",
    "        Returns:\n",
    "            Output logits of shape (batch_size, num_classes)\n",
    "        \"\"\"\n",
    "        # First fully-connected layer + ReLU activation\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Second fully-connected layer + ReLU activation\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        # Output layer (no activation, will be used with CrossEntropyLoss)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597115f3",
   "metadata": {},
   "source": [
    "### Understanding the Network Architecture\n",
    "\n",
    "Our network has the following structure:\n",
    "\n",
    "1. **Input Layer**: 42 features (hand landmarks)\n",
    "2. **Hidden Layer 1**: 256 neurons → ReLU activation\n",
    "3. **Hidden Layer 2**: 128 neurons → ReLU activation\n",
    "4. **Output Layer**: 2 neurons (one for each ASL letter)\n",
    "\n",
    "The `forward` method defines the forward pass of the input through the neural network:\n",
    "- Each layer applies the linear transformation: $z = Wx + b$\n",
    "- ReLU activation introduces non-linearity: $h = \\max(0, z)$\n",
    "- The final layer outputs raw scores (logits) without activation\n",
    "\n",
    "The backward pass is automatically defined by PyTorch based on the definition of the forward pass, using a process called [automatic differentiation](https://docs.pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html) to keep track of operations using a computational graph.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81fb8fc1",
   "metadata": {},
   "source": [
    "\n",
    "## Training\n",
    "Neural networks are trained using:\n",
    "- **Loss Function**: Measures how wrong predictions are (Cross-Entropy Loss for classification)\n",
    "- **Optimizer**: Updates weights using gradient descent (SGD, Adam)\n",
    "- **Mini-Batch Training**: Updates on small batches of data for efficiency\n",
    "- **Epochs**: Full passes through the training data\n",
    "\n",
    "## Training Loop\n",
    "\n",
    "To train a neural network, we need to:\n",
    "1. Define a **loss function** to measure prediction error\n",
    "2. Define an **optimizer** to update weights based on gradients\n",
    "3. Iterate through data in **mini-batches** for efficient training\n",
    "4. Update weights using **backpropagation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2606fa05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model, loss function, and optimizer\n",
    "model = AvB_Model(input_features=42, num_classes=2)\n",
    "model.to(device)\n",
    "\n",
    "# CrossEntropyLoss combines softmax and negative log-likelihood\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "# The Adam optimizer tends to converge much \n",
    "# more quickly with this dataset compared to \n",
    "# using Stochastic Gradient Descent\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Model:\\n{model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdcfc10",
   "metadata": {},
   "source": [
    "### The Training Loop\n",
    "\n",
    "The standard PyTorch training loop follows this pattern:\n",
    "\n",
    "```python\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        # 1. Forward pass: compute predictions\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # 2. Compute loss\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # 3. Backward pass: compute gradients\n",
    "        optimizer.zero_grad()  # Clear old gradients\n",
    "        loss.backward()        # Compute new gradients\n",
    "        \n",
    "        # 4. Update weights\n",
    "        optimizer.step()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711bc6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "num_epochs = 10\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "val_losses = []\n",
    "val_accuracies = []\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_train_loss = 0.0\n",
    "    epoch_train_correct = 0\n",
    "    epoch_train_total = 0\n",
    "    \n",
    "    for landmarks, labels in train_loader:\n",
    "        landmarks = landmarks.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()              # reset gradients\n",
    "        outputs = model(landmarks)         # make a prediction using the model (forward pass)\n",
    "        loss = criterion(outputs, labels)  # compare predictions to ground truth labels\n",
    "        loss.backward()                    # calculate gradients (backward pass)\n",
    "        optimizer.step()                   # update parameters\n",
    "        \n",
    "        # Track metrics\n",
    "        epoch_train_loss += loss.item() * landmarks.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        epoch_train_correct += (predicted == labels).sum().item()\n",
    "        epoch_train_total += labels.size(0)\n",
    "    \n",
    "    # Average training metrics for epoch\n",
    "    avg_train_loss = epoch_train_loss / epoch_train_total\n",
    "    avg_train_acc = epoch_train_correct / epoch_train_total\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(avg_train_acc)\n",
    "    \n",
    "    # set model to eval mode (no updating of weights)\n",
    "    model.eval()\n",
    "    epoch_val_loss = 0.0\n",
    "    epoch_val_correct = 0\n",
    "    epoch_val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # check performance on validation dataset\n",
    "        for landmarks, labels in val_loader:\n",
    "            landmarks = landmarks.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            outputs = model(landmarks)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            epoch_val_loss += loss.item() * landmarks.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            epoch_val_correct += (predicted == labels).sum().item()\n",
    "            epoch_val_total += labels.size(0)\n",
    "    \n",
    "    # Average validation metrics for epoch\n",
    "    avg_val_loss = epoch_val_loss / epoch_val_total\n",
    "    avg_val_acc = epoch_val_correct / epoch_val_total\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(avg_val_acc)\n",
    "    \n",
    "    # Print progress\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] - \"\n",
    "          f\"Train Loss: {avg_train_loss:.4f}, Train Acc: {avg_train_acc*100:.2f}% | \"\n",
    "          f\"Val Loss: {avg_val_loss:.4f}, Val Acc: {avg_val_acc*100:.2f}%\")\n",
    "\n",
    "save_path = \"./AvB_fc_model.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"saved model to {save_path}: {val_accuracies[-1]:.2f}% accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4f298e",
   "metadata": {},
   "source": [
    "## Visualizing Training Progress\n",
    "\n",
    "Let's plot the training and validation curves to understand how well our model is learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf07a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "epochs_range = np.arange(len(train_losses))\n",
    "plt.plot(epochs_range, train_losses, label='Training Loss', marker='o')\n",
    "plt.plot(epochs_range, val_losses, label='Validation Loss', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, np.array(train_accuracies) * 100, label='Training Accuracy', marker='o')\n",
    "plt.plot(epochs_range, np.array(val_accuracies) * 100, label='Validation Accuracy', marker='s')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Training Accuracy: {train_accuracies[-1]*100:.2f}%\")\n",
    "print(f\"Validation Accuracy: {val_accuracies[-1]*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d0e1dd",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "The below code implements a live webcam loop, which processes each frame from your webcamera using a provided `ImageToTensorPreprocessor` class to convert video frames containing hands to hand landmark tensors. If a hand is detected, the landmarks are provided as input to your trained model, and the result is drawn on the video frame before it is then show on the screen with `cv2.imshow(\"Image\", annotated_img)`\n",
    "\n",
    "**Note:** Here, we process the output of the model using `torch.softmax`, instead of our loss function from before `torch.CrossEntropyLoss`.\n",
    "\n",
    "**Note:** This cell will not work if you are running your notebook on Google Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce8e80",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from dataloader import ImageToTensorPreprocessor, label_to_letter\n",
    "\n",
    "model = AvB_Model()\n",
    "model.load_state_dict(torch.load(\"AvB_fc_model.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "find_hands = ImageToTensorPreprocessor(output_format=\"landmarks\", static_image_mode=False)\n",
    "while True:\n",
    "    success, annotated_img = cap.read()\n",
    "    annotated_img = cv2.flip(annotated_img, 1)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    landmarks = find_hands(annotated_img)\n",
    "    if landmarks is not None:\n",
    "        landmarks = landmarks.to(device)\n",
    "        classification = model(landmarks)\n",
    "        predicted_label = torch.argmax(classification, dim=-1).item()\n",
    "        predicted_letter = label_to_letter(predicted_label)\n",
    "        confidence = torch.softmax(classification, dim=-1).max().item() * 100\n",
    "\n",
    "        annotated_img = find_hands.draw_hand_landmarks(\n",
    "            annotated_img,\n",
    "            text = f\"Predicted: {predicted_letter} ({confidence:.1f}%)\"\n",
    "        )\n",
    "    cv2.imshow(\"Image\", annotated_img)\n",
    "    if key == ord(\"q\"):\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cce423b",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "Dropout is a regularization technique that randomly zeros out neurons during training to prevent overfitting:\n",
    "\n",
    "During classification, all neurons are used, with activations scaled by $1/(1-p)$\n",
    "\n",
    "```python\n",
    "dropout = nn.Dropout(0.5)  # Randomly drop 50% of neurons\n",
    "\n",
    "\n",
    "class AvB_Model(torch.nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(AvB_Model, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(42, 256)\n",
    "        self.fc2 = torch.nn.Linear(256, 128)\n",
    "        self.fc3 = torch.nn.Linear(128, num_classes)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0b919",
   "metadata": {},
   "source": [
    "## Adam Optimizer (Adaptive Moment Estimation)\n",
    "\n",
    "The Adam optimizer improves performance over SGD by adaptively adjusting individual learning rates for each parameter using estimates of first and second gradient moments, which typically leads to faster and more stable convergence.\n",
    "\n",
    "```python\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
